import numpy as np
import pandas as pd
import sklearn
import seaborn as sns
import matplotlib.pyplot as plt
get_ipython().magic('matplotlib inline')
from sklearn.linear_model import LogisticRegression


# In[2]:


test_set = pd.read_csv('test.csv')
test_set.head(3)


# In[3]:


submission_example = pd.read_csv('gender_submission.csv')
submission_example.head(3)


# In[4]:


train_set = pd.read_csv('train.csv')
train_set.head()


# In[5]:


test_set.head()


# In[6]:


#feature analysis
print(train_set['Sex'].value_counts())
print(train_set['Pclass'].value_counts())
print(train_set['Embarked'].value_counts())
print(train_set['Survived'].value_counts())


# In[7]:


train_set.drop(['PassengerId','Name','Cabin','Ticket'],axis=1,inplace=True)
test_set.drop(['PassengerId','Name','Cabin','Ticket'],axis=1,inplace=True)


# In[8]:


sns.heatmap(train_set.isnull(),yticklabels=False,cbar=False,cmap='viridis') #around 20% of data is missing


# In[9]:


plt.figure(figsize=(12, 7))
sns.boxplot(x='Pclass',y='Age',data=train_set,palette='winter')


# In[10]:


#based on plt above and pclass we will reconstruct to missing age data
def impute_age(cols):
    Age = cols[0]
    Pclass = cols[1]
    
    if pd.isnull(Age):

        if Pclass == 1:
            return 37

        elif Pclass == 2:
            return 29

        else:
            return 24

    else:
        return Age


# In[11]:


train_set['Age'] = train_set[['Age','Pclass']].apply(impute_age,axis=1)
test_set['Age'] = test_set[['Age','Pclass']].apply(impute_age,axis=1)


# In[12]:


sns.heatmap(train_set.isnull(),yticklabels=False,cbar=False,cmap='viridis') #data set is complete


# In[13]:


sns.heatmap(test_set.isnull(),yticklabels=False,cbar=False,cmap='viridis') #data set is complete


# In[14]:


print(test_set.head(5))
print(train_set.head(5))


# In[15]:


test_set.head()


# In[16]:


train_set = pd.get_dummies(data=train_set, dummy_na=True, columns= ['Sex', 'Embarked'])


# In[17]:


test_set = pd.get_dummies(data=test_set, dummy_na=True, columns= ['Sex', 'Embarked'])


# In[18]:


train_set.head()


# In[19]:


train_set.drop('Embarked_nan', axis=1,inplace=True)
test_set.drop('Embarked_nan', axis=1,inplace=True)


# In[20]:


train_set.drop('Sex_nan', axis=1,inplace=True)
test_set.drop('Sex_nan', axis=1,inplace=True)


# In[21]:


train_set.head() #final train set


# In[22]:


# impute missing values by mean on train and test set
train_set.fillna(train_set.mean(),inplace=True)
train_set.isnull().values.any()
test_set.fillna(train_set.mean(),inplace=True)
#Checking for nan values
test_set.isnull().values.any()


# In[23]:


test_set.info()


# In[24]:


X = train_set.iloc[:,1:12].values
y = train_set.iloc[:,0].values
X_test = test_set.iloc[:,:].values


# In[25]:


from sklearn.model_selection import train_test_split
X_train , X_validate , y_train , y_validate = train_test_split(X,y,test_size=0.18,random_state=42)


# In[26]:


from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_validate = sc_X.transform(X_validate)


# In[27]:


from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=1000,min_samples_split=30,min_samples_leaf=4,random_state=42,warm_start=True)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_validate)


# In[28]:


#metrics
from sklearn.metrics import confusion_matrix
cnf = confusion_matrix(y_validate,y_pred)
print(cnf)
acu = (216/268)*100 #Out of 268 validation set 216(146+70) predictions are right
print(acu)


# In[29]:


#Now applying Model Total dataset and testing on test data
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X = sc_X.fit_transform(X)
X_test = sc_X.transform(X_test)

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=1000,min_samples_split=30,min_samples_leaf=4,random_state=42,warm_start=True)
clf.fit(X,y)


# In[30]:


#Predicting the survial on test set
y_predict = clf.predict(X_test)


# In[31]:


y_predict
